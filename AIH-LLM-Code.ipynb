{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CocpcVJSUgCw"
      },
      "source": [
        "**Section 1: Install OpenAI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkLDvjvAsrBd",
        "outputId": "b773f73c-f7ab-4b07-b777-1bbb96b401cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from openai) (3.11.16)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests>=2.20->openai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests>=2.20->openai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from requests>=2.20->openai) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from aiohttp->openai) (1.19.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\syyad\\miniconda3\\envs\\dl_hw\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Section 2: Load Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWqXWi2JuIYc",
        "outputId": "c47f56db-b5bb-4c7c-f9e6-a7d73eb13a02"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, RocCurveDisplay\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KGHcEyWHB50"
      },
      "source": [
        "**Section 3: Initialize the OpenAI Client with my API Key**\n",
        "Note: Key masked in final code for privacy reasons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmpxOboEfoj4"
      },
      "outputs": [],
      "source": [
        "openai.api_key = 'xxxxxxxx' # Key masked for privacy. Replace it with your own API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Section 3: Chain-of-thought (CoT) Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Identifying the symptoms - The patient is experiencing sneezing, itchy eyes, and a runny nose. These are common symptoms of an allergic reaction or a respiratory infection.\n",
            "\n",
            "Step 2: Considering common conditions - All of these symptoms are typical of allergic rhinitis, also known as hay fever, which is an allergic response to certain allergens, such as pollen, dust mites, or pet dander. It could also indicate a common cold or flu, which are viral infections.\n",
            "\n",
            "Step 3: Considering other factors - If the patient's symptoms are seasonal or occur after exposure to certain environments or substances, an allergy is more likely. If the patient also has a fever or body aches, a viral infection like the flu may be more likely.\n",
            "\n",
            "Step 4: Next steps - The patient should be asked about other symptoms, the duration and timing of these symptoms, and any known allergies. A physical examination may also be performed. An allergy test could help confirm an allergic reaction, while a nasal or throat swab could help diagnose a viral infection.\n",
            "\n",
            "Step 5: Conclusion - While the exact condition cannot be confirmed without further information and tests, the patient's symptoms of sneezing, itchy eyes, and a runny nose most commonly suggest an allergic reaction or a viral respiratory infection.\n"
          ]
        }
      ],
      "source": [
        "prompt_cot = \"\"\"\n",
        "Patient reports sneezing, itchy eyes, and a runny nose.\n",
        "\n",
        "Let's think step-by-step about what this could indicate.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt_cot}\n",
        "    ],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Section 4: Train-of-thought (ToT) Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Peanut Allergy: This is a type of food allergy where the immune system overreacts to proteins in peanuts. Symptoms can range from mild, such as hives and itching, to severe, such as shortness of breath and swelling, which can cause anaphylaxis - a life-threatening allergic reaction.\n",
            "\n",
            "2. Asthma: Shortness of breath can be a symptom of asthma, but it's usually accompanied by wheezing and tightness in the chest. The hives and swelling after eating peanuts could be a coincidence and not related to the respiratory issues.\n",
            "\n",
            "3. Anaphylaxis: This is a severe and potentially life-threatening allergic reaction that can occur within seconds or minutes of exposure to something you're allergic to, such as peanuts. Symptoms include hives, swelling, shortness of breath, low blood pressure, and potential loss of consciousness.\n",
            "\n",
            "The most likely condition is a Peanut Allergy, specifically leading to Anaphylaxis. The timing of the symptoms (occurring after eating peanuts) as well as the specific symptoms themselves (hives, swelling, shortness of breath) all point to an allergic reaction to peanuts. Asthma usually has additional symptoms and wouldn't explain the hives and swelling. While anaphylaxis is a part of the reaction, it's more of a severe symptom of the underlying cause - in this case, the peanut allergy. This means the patient should avoid peanuts and carry an epinephrine auto-injector (EpiPen) to treat any accidental exposures.\n"
          ]
        }
      ],
      "source": [
        "prompt_tot = \"\"\"\n",
        "The patient has these symptoms: shortness of breath, hives, and swelling after eating peanuts.\n",
        "\n",
        "Think of three possible conditions this could be and explain each.\n",
        "\n",
        "Then pick the most likely one and justify your reasoning.\n",
        "\"\"\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt_tot}\n",
        "    ],\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "print(response['choices'][0]['message']['content'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Section 5: Generating One Shot Prompts for GPT-4 from the Dataset and Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import openai\n",
        "import re\n",
        "\n",
        "# 1. Category mapping \n",
        "CATEGORY_MAP = {\n",
        "    \"soya bean (substance)\": \"food\",\n",
        "    \"peanut (substance)\": \"food\",\n",
        "    \"shrimp (substance)\": \"food\",\n",
        "    \"penicillin v\": \"medication\",\n",
        "    \"amoxicillin\": \"medication\",\n",
        "    \"mold (organism)\": \"mold (organism)\",\n",
        "    \"animal dander (substance)\": \"animal dander (substance)\"\n",
        "}\n",
        "\n",
        "# 2. Normalize categories\n",
        "def normalize_diag(diagnosis):\n",
        "    diagnosis = diagnosis.lower().strip()\n",
        "    return CATEGORY_MAP.get(diagnosis, diagnosis)\n",
        "\n",
        "# 3. Extract answer from GPT response\n",
        "def extract_diagnosis(gpt_response):\n",
        "    match = re.search(r\"diagnosis\\s*[:\\-]?\\s*(.+)\", gpt_response, re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else gpt_response.strip()\n",
        "\n",
        "# 4. Call GPT\n",
        "def call_gpt(prompt, model=\"gpt-4\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# 5. One-shot generator from dataset\n",
        "def generate_one_shot_prompt_from_dataset(csv_path, choices=None):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    valid = df.dropna(subset=[\"DESCRIPTION\", \"DESCRIPTION1\"])\n",
        "    sample_rows = valid.sample(n=2, random_state=random.randint(1, 10000))\n",
        "    train_row, test_row = sample_rows.iloc[0], sample_rows.iloc[1]\n",
        "\n",
        "    train_symptoms = train_row[\"DESCRIPTION1\"]\n",
        "    if pd.notna(train_row.get(\"DESCRIPTION2\")):\n",
        "        train_symptoms += f\", {train_row['DESCRIPTION2']}\"\n",
        "    train_diagnosis = train_row[\"DESCRIPTION\"]\n",
        "\n",
        "    test_symptoms = test_row[\"DESCRIPTION1\"]\n",
        "    if pd.notna(test_row.get(\"DESCRIPTION2\")):\n",
        "        test_symptoms += f\", {test_row['DESCRIPTION2']}\"\n",
        "    true_diagnosis = test_row[\"DESCRIPTION\"]\n",
        "\n",
        "    choice_text = \"\"\n",
        "    if choices:\n",
        "        choice_text = \"\\nChoose one of the following diagnoses:\\n- \" + \"\\n- \".join(choices)\n",
        "\n",
        "    prompt = f\"\"\"Example:\n",
        "Symptoms: {train_symptoms}\n",
        "Diagnosis: {train_diagnosis}\n",
        "\n",
        "Now, analyze this:\n",
        "Symptoms: {test_symptoms}{choice_text}\n",
        "Diagnosis:\"\"\"\n",
        "\n",
        "    return prompt, true_diagnosis\n",
        "\n",
        "# 6. Full test function\n",
        "def run_one_shot_test(csv_path, choices):\n",
        "    prompt, true_label = generate_one_shot_prompt_from_dataset(csv_path, choices)\n",
        "    gpt_response = call_gpt(prompt)\n",
        "    predicted_diagnosis = extract_diagnosis(gpt_response)\n",
        "\n",
        "    true_norm = normalize_diag(true_label)\n",
        "    pred_norm = normalize_diag(predicted_diagnosis)\n",
        "\n",
        "    is_correct = true_norm == pred_norm\n",
        "\n",
        "    print(\"=== One-Shot Prompt ===\")\n",
        "    print(prompt)\n",
        "    print(\"\\n=== GPT Response ===\")\n",
        "    print(gpt_response)\n",
        "    print(\"\\nTrue Diagnosis:\", true_label)\n",
        "    print(\"Predicted Diagnosis:\", predicted_diagnosis)\n",
        "    print(\"Correct:\", is_correct)\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"response\": gpt_response,\n",
        "        \"true\": true_label,\n",
        "        \"predicted\": predicted_diagnosis,\n",
        "        \"normalized_true\": true_norm,\n",
        "        \"normalized_pred\": pred_norm,\n",
        "        \"correct\": is_correct\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== One-Shot Prompt ===\n",
            "Example:\n",
            "Symptoms: Wheal (finding)\n",
            "Diagnosis: Cow's milk (substance)\n",
            "\n",
            "Now, analyze this:\n",
            "Symptoms: Nausea (finding), Eruption of skin (disorder)\n",
            "Choose one of the following diagnoses:\n",
            "- Mold (organism)\n",
            "- Animal dander (substance)\n",
            "- Penicillin V\n",
            "- Food\n",
            "- Medication\n",
            "- Other (specify)\n",
            "Diagnosis:\n",
            "\n",
            "=== GPT Response ===\n",
            "Diagnosis: Food\n",
            "\n",
            "The symptoms of nausea and skin eruption are commonly associated with food allergies or intolerances. Food is a more likely diagnosis given the symptoms presented.\n",
            "\n",
            "True Diagnosis: Shellfish (substance)\n",
            "Predicted Diagnosis: Food\n",
            "Correct: False\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'prompt': \"Example:\\nSymptoms: Wheal (finding)\\nDiagnosis: Cow's milk (substance)\\n\\nNow, analyze this:\\nSymptoms: Nausea (finding), Eruption of skin (disorder)\\nChoose one of the following diagnoses:\\n- Mold (organism)\\n- Animal dander (substance)\\n- Penicillin V\\n- Food\\n- Medication\\n- Other (specify)\\nDiagnosis:\",\n",
              " 'response': 'Diagnosis: Food\\n\\nThe symptoms of nausea and skin eruption are commonly associated with food allergies or intolerances. Food is a more likely diagnosis given the symptoms presented.',\n",
              " 'true': 'Shellfish (substance)',\n",
              " 'predicted': 'Food',\n",
              " 'normalized_true': 'shellfish (substance)',\n",
              " 'normalized_pred': 'food',\n",
              " 'correct': False}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "openai.api_key = 'xxxxxxxx' # Key masked for privacy. Replace it with your own API.\n",
        "choices = [\"Mold (organism)\", \"Animal dander (substance)\", \"Penicillin V\", \"Food\", \"Medication\", \"Other (specify)\"]\n",
        "run_one_shot_test(\"C:/Users/SYYAD/Documents/MSAI/AI in Healthcare/LLM/synthea_sample_data_csv_nov2021/csv/allergies.csv\", choices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Section 6: Generating Few Shot Prompts for GPT-4 from the Dataset and Predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "        START  STOP                               PATIENT  \\\n",
            "0  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
            "1  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
            "2  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
            "3  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
            "4  2020-02-17   NaN  b9c610cd-28a6-4636-ccb6-c7a0d2a4cb85   \n",
            "\n",
            "                              ENCOUNTER       CODE   SYSTEM  \\\n",
            "0  01efcc52-15d6-51e9-faa2-bee069fcbe44  111088007  Unknown   \n",
            "1  01efcc52-15d6-51e9-faa2-bee069fcbe44   84489001  Unknown   \n",
            "2  01efcc52-15d6-51e9-faa2-bee069fcbe44  260147004  Unknown   \n",
            "3  01efcc52-15d6-51e9-faa2-bee069fcbe44  264287008  Unknown   \n",
            "4  01efcc52-15d6-51e9-faa2-bee069fcbe44  256277009  Unknown   \n",
            "\n",
            "                  DESCRIPTION     TYPE     CATEGORY    REACTION1  \\\n",
            "0           Latex (substance)  allergy  environment  247472004.0   \n",
            "1             Mold (organism)  allergy  environment   76067001.0   \n",
            "2  House dust mite (organism)  allergy  environment          NaN   \n",
            "3   Animal dander (substance)  allergy  environment  878820003.0   \n",
            "4    Grass pollen (substance)  allergy  environment          NaN   \n",
            "\n",
            "                     DESCRIPTION1 SEVERITY1    REACTION2  \\\n",
            "0                 Wheal (finding)      MILD          NaN   \n",
            "1                        Sneezing      MILD          NaN   \n",
            "2                             NaN       NaN          NaN   \n",
            "3  Rhinoconjunctivitis (disorder)  MODERATE  271807003.0   \n",
            "4                             NaN       NaN          NaN   \n",
            "\n",
            "                  DESCRIPTION2 SEVERITY2  \n",
            "0                          NaN       NaN  \n",
            "1                          NaN       NaN  \n",
            "2                          NaN       NaN  \n",
            "3  Eruption of skin (disorder)      MILD  \n",
            "4                          NaN       NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load allergies.csv\n",
        "df = pd.read_csv('C:/Users/SYYAD/Documents/MSAI/AI in Healthcare/LLM/synthea_sample_data_csv_nov2021/csv/allergies.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Complete: Accuracy = 34.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\SYYAD\\AppData\\Local\\Temp\\ipykernel_15128\\2210212626.py:101: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  (df_source[\"DESCRIPTION1\"].str.lower().str.contains(row[\"Symptoms\"].split(',')[0].lower(), na=False))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\SYYAD\\miniconda3\\envs\\dl_hw\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix and classification report saved.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import openai\n",
        "import re\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# OpenAI key\n",
        "openai.api_key = 'xxxxxxxx' # Key masked for privacy. Replace it with your own API.\n",
        "\n",
        "# Load allergy dataset\n",
        "df_allergies = pd.read_csv(\"C:/Users/SYYAD/Documents/MSAI/AI in Healthcare/LLM/synthea_sample_data_csv_nov2021/csv/allergies.csv\")\n",
        "valid_cases = df_allergies.dropna(subset=[\"DESCRIPTION\", \"DESCRIPTION1\", \"DESCRIPTION2\"])\n",
        "\n",
        "# Direct diagnosis with choices\n",
        "def generate_direct_diagnosis_prompt(df, test_symptoms, choices=None, num_examples=5):\n",
        "    valid = df.dropna(subset=[\"DESCRIPTION\", \"DESCRIPTION1\", \"DESCRIPTION2\"])\n",
        "    examples = valid.sample(n=num_examples, random_state=42)\n",
        "\n",
        "    prompt_parts = []\n",
        "    for _, row in examples.iterrows():\n",
        "        s1 = row[\"DESCRIPTION1\"]\n",
        "        s2 = row[\"DESCRIPTION2\"] if pd.notna(row[\"DESCRIPTION2\"]) else \"\"\n",
        "        symptoms = f\"{s1}, {s2}\" if s2 else s1\n",
        "        diagnosis = row[\"DESCRIPTION\"]\n",
        "        prompt_parts.append(f\"Example:\\nSymptoms: {symptoms}\\nDiagnosis: {diagnosis}\")\n",
        "\n",
        "    choice_text = \"\"\n",
        "    if choices:\n",
        "        choice_text = \"\\nChoose one of the following diagnoses:\\n- \" + \"\\n- \".join(choices)\n",
        "\n",
        "    test_prompt = (\n",
        "        f\"\\nNow, analyze this:\\nSymptoms: {test_symptoms}{choice_text}\\n\"\n",
        "        \"Diagnosis:\"\n",
        "    )\n",
        "    return \"\\n\\n\".join(prompt_parts) + \"\\n\\n\" + test_prompt\n",
        "\n",
        "# Call GPT\n",
        "def call_gpt(prompt, model=\"gpt-4o\"):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Extract diagnosis from GPT reply\n",
        "def extract_diagnosis(gpt_response):\n",
        "    match = re.search(r\"diagnosis\\s*[:\\-]\\s*(.+)\", gpt_response, re.IGNORECASE)\n",
        "    return match.group(1).strip() if match else gpt_response.strip()\n",
        "\n",
        "# Evaluate accuracy\n",
        "def evaluate_predictions(df, test_cases, choices, num_examples=5, model=\"gpt-4\"):\n",
        "    logs = []\n",
        "    correct_count = 0\n",
        "\n",
        "    for i, (symptoms, true_diagnosis) in enumerate(test_cases):\n",
        "        prompt = generate_direct_diagnosis_prompt(df, symptoms, choices, num_examples)\n",
        "        gpt_output = call_gpt(prompt)\n",
        "        predicted_diagnosis = extract_diagnosis(gpt_output)\n",
        "\n",
        "        is_correct = predicted_diagnosis.lower() == true_diagnosis.lower()\n",
        "        correct_count += int(is_correct)\n",
        "\n",
        "        logs.append({\n",
        "            \"Case\": i + 1,\n",
        "            \"Symptoms\": symptoms,\n",
        "            \"True Diagnosis\": true_diagnosis,\n",
        "            \"Predicted Diagnosis\": predicted_diagnosis,\n",
        "            \"Correct\": is_correct,\n",
        "            \"Raw GPT Output\": gpt_output,\n",
        "            \"Prompt Used\": prompt\n",
        "        })\n",
        "\n",
        "    accuracy = correct_count / len(test_cases)\n",
        "    result_df = pd.DataFrame(logs)\n",
        "    result_df.to_csv(\"gpt_diagnosis_results.csv\", index=False)\n",
        "    print(f\"Evaluation Complete: Accuracy = {accuracy:.2%}\")\n",
        "    return result_df\n",
        "\n",
        "# Add confidence + severity awareness\n",
        "def extract_confidence(response_text):\n",
        "    if \"likely\" in response_text.lower():\n",
        "        return \"High\"\n",
        "    elif \"possible\" in response_text.lower() or \"maybe\" in response_text.lower():\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Uncertain\"\n",
        "\n",
        "def add_confidence_and_severity(results_df, df_source):\n",
        "    confidences = []\n",
        "    severities = []\n",
        "\n",
        "    for _, row in results_df.iterrows():\n",
        "        raw = row[\"Raw GPT Output\"]\n",
        "        conf = extract_confidence(raw)\n",
        "        confidences.append(conf)\n",
        "\n",
        "        match = df_source[\n",
        "            (df_source[\"DESCRIPTION\"].str.lower() == row[\"True Diagnosis\"].lower()) &\n",
        "            (df_source[\"DESCRIPTION1\"].str.lower().str.contains(row[\"Symptoms\"].split(',')[0].lower(), na=False))\n",
        "        ]\n",
        "        if not match.empty:\n",
        "            severities.append(match.iloc[0][\"SEVERITY1\"])\n",
        "        else:\n",
        "            severities.append(\"Unknown\")\n",
        "\n",
        "    results_df[\"Confidence\"] = confidences\n",
        "    results_df[\"Severity\"] = severities\n",
        "    return results_df\n",
        "\n",
        "# Confusion matrix + classification report\n",
        "def analyze_results(results_df):\n",
        "    y_true = results_df[\"True Diagnosis\"].str.lower()\n",
        "    y_pred = results_df[\"Predicted Diagnosis\"].str.lower()\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=y_true.unique())\n",
        "    report = classification_report(y_true, y_pred, output_dict=True)\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=y_true.unique(), yticklabels=y_true.unique(), cmap='Blues')\n",
        "    plt.title(\"GPT Diagnosis Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    report_df.to_csv(\"classification_report.csv\")\n",
        "    print(\"Confusion matrix and classification report saved.\")\n",
        "\n",
        "# Sample test data from dataset\n",
        "test_cases = []\n",
        "sample = valid_cases.sample(50, random_state=100)\n",
        "#print(sample.head())\n",
        "for _, row in sample.iterrows():\n",
        "    s1 = row[\"DESCRIPTION1\"]\n",
        "    s2 = row[\"DESCRIPTION2\"] if pd.notna(row[\"DESCRIPTION2\"]) else \"\"\n",
        "    symptoms = f\"{s1}, {s2}\" if s2 else s1\n",
        "    #print(symptoms)\n",
        "    test_cases.append((symptoms, row[\"DESCRIPTION\"]))\n",
        "\n",
        "# Define choices\n",
        "choices = [\"Animal dander (substance)\", \"Aspirin\", \"Bee venom (substance)\", \"cefdinir\", \"Cow's milk (substance)\", \"Eggs (edible) (substance)\", \"Fish (substance)\", \"Grass pollen (substance)\", \"House dust mite (organism)\", \"Ibuprofen\", \"Latex (substance)\", \"Lisinopril\", \"Mold (organism)\", \"Peanut (substance)\", \"Penicillin V\", \"Shellfish (substance)\", \"Soya bean (substance)\", \"Sulfamethoxazole / Trimethoprim\", \"Tree nut (substance)\", \"Tree pollen (substance)\", \"Wheat (substance)\"]\n",
        "\n",
        "# Run everything\n",
        "results_df = evaluate_predictions(valid_cases, test_cases, choices)\n",
        "results_df = add_confidence_and_severity(results_df, df_allergies)\n",
        "analyze_results(results_df)\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl_hw",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
